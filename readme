hiiiii â˜»
my first github repository so cool
git is so woah, i feel like a linux user.

This is my attempt at creating a neural network to identify handwritten digits using the MNIST database.
I have reached a point where I cannot seem to figure out the issue for the overfitting, i realized its not overfitting to the first input but its converging(?) to 5.
It prefers 5 as an output for some reason. Probably a huge oversight somewhere in the math.
I hate to say this but I am officially giving up until the future, Inshallah. I have to revisit this and finish it.


I FELT IT IN MY REACH, I SWITHCED FROM MSE TO CROSS-ENTROPY BUT MADE A MISTAKE IN THE MATHEMATICS SOMEWHERE NOOOOOOOOOOOOOOOOOOO.
I should have just given up eariler and resumed when I have ample time.

That'll be the first thing on my TODO list for when I continue.


TODO:
Fix cross-entropy
Add regularization and dropout if its still overfitting weirdly
Cry
