#  2-Layer Neural Network From Scratch  | MNIST Database 

## Contents
### Interfacer
- Opens a canvas where any digit drawn will be guessed by the network.

### Activation functions
- Hidden layer: ReLU
- Output layer: Sigmoid

### Optimizer
- Adam


## Motivation for project
I initially wanted to create a network that could solve a Rubik's cube, however I had zero knowledge on how neural networks actually worked. This sparked the idea of creating my own multiclass classification model from scratch without relying on libraries such as Pytorch or Tensorflow. This allowed me to understand the core fundamentals and further develop my problem solving skills.

  
## References
_to be added_

- **The Complete Mathematics of Neural Networks and Deep Learning.** https://www.youtube.com/watch?v=Ixl3nykKG9M 

- http://neuralnetworksanddeeplearning.com/chap1.html
- https://github.com/kdexd/digit-classifier/blob/master/network.py
